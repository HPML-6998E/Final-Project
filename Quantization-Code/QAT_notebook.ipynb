{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6d7cf6288f514123978acaa25e37db6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72e8bd0998ab43afb0776e81b7312493",
              "IPY_MODEL_0da44bea017a4508a250c9d82e8966f0",
              "IPY_MODEL_47657b193af8467f84473765ab23275b"
            ],
            "layout": "IPY_MODEL_377af52186e047d5aba3cd223709bdba"
          }
        },
        "72e8bd0998ab43afb0776e81b7312493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_338b7061fc644aff853f37565c75f097",
            "placeholder": "​",
            "style": "IPY_MODEL_53365016a23f4e8e93da52f591d9c8ac",
            "value": "config.json: 100%"
          }
        },
        "0da44bea017a4508a250c9d82e8966f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61eb6ae6135147e4ab40ef2de72d2ed3",
            "max": 69665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d0a12464f204d6f8463a7dffe07e8ec",
            "value": 69665
          }
        },
        "47657b193af8467f84473765ab23275b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d904517fc58849ef9112c9c1391fd174",
            "placeholder": "​",
            "style": "IPY_MODEL_b2a6203855664a7c84fedc98b0b61de3",
            "value": " 69.7k/69.7k [00:00&lt;00:00, 3.53MB/s]"
          }
        },
        "377af52186e047d5aba3cd223709bdba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "338b7061fc644aff853f37565c75f097": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53365016a23f4e8e93da52f591d9c8ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61eb6ae6135147e4ab40ef2de72d2ed3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d0a12464f204d6f8463a7dffe07e8ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d904517fc58849ef9112c9c1391fd174": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2a6203855664a7c84fedc98b0b61de3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea4aea8ed0814bba97f128097ec5ccf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b24ac43b5c434e6784edf164830b01bd",
              "IPY_MODEL_eb439848569e46769bb53fa55daa7eb7",
              "IPY_MODEL_71f39f9e61254218b5d47035c7b5cee4"
            ],
            "layout": "IPY_MODEL_84186bddfc5246d5a85cfaab1bfd7e38"
          }
        },
        "b24ac43b5c434e6784edf164830b01bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2488d88721446a7b41d87d76606560a",
            "placeholder": "​",
            "style": "IPY_MODEL_68508f3c7f784b1f9489bea9ddfdef74",
            "value": "model.safetensors: 100%"
          }
        },
        "eb439848569e46769bb53fa55daa7eb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14786981eafa42c48b71fefb288da142",
            "max": 346293852,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bc8cd564dbe441db44647f1b0dfc72a",
            "value": 346293852
          }
        },
        "71f39f9e61254218b5d47035c7b5cee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f184c14577cb40ddb911483c4aaa3ee7",
            "placeholder": "​",
            "style": "IPY_MODEL_228fd49e77f345d7a143e38cad3e3da2",
            "value": " 346M/346M [00:01&lt;00:00, 240MB/s]"
          }
        },
        "84186bddfc5246d5a85cfaab1bfd7e38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2488d88721446a7b41d87d76606560a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68508f3c7f784b1f9489bea9ddfdef74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14786981eafa42c48b71fefb288da142": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bc8cd564dbe441db44647f1b0dfc72a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f184c14577cb40ddb911483c4aaa3ee7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "228fd49e77f345d7a143e38cad3e3da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZKVwULDG_JX3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.ao.quantization as quant\n",
        "from torch.ao.quantization import get_default_qat_qconfig, prepare_qat, convert\n",
        "from torch.ao.quantization.qconfig import QConfig\n",
        "from torch.ao.quantization.observer import MinMaxObserver\n",
        "\n",
        "from transformers import ViTForImageClassification\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.transforms import InterpolationMode\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from tqdm import tqdm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "28xjdDLE_KMe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pretrained ViT model from Hugging Face\n",
        "model_name = \"google/vit-base-patch16-224\"\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    model_name,\n",
        "    ignore_mismatched_sizes=True,\n",
        ")\n",
        "\n",
        "# Modify the classifier to match the Food101 dataset (101 classes)\n",
        "model.classifier = nn.Linear(model.config.hidden_size, 101)\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210,
          "referenced_widgets": [
            "6d7cf6288f514123978acaa25e37db6f",
            "72e8bd0998ab43afb0776e81b7312493",
            "0da44bea017a4508a250c9d82e8966f0",
            "47657b193af8467f84473765ab23275b",
            "377af52186e047d5aba3cd223709bdba",
            "338b7061fc644aff853f37565c75f097",
            "53365016a23f4e8e93da52f591d9c8ac",
            "61eb6ae6135147e4ab40ef2de72d2ed3",
            "9d0a12464f204d6f8463a7dffe07e8ec",
            "d904517fc58849ef9112c9c1391fd174",
            "b2a6203855664a7c84fedc98b0b61de3",
            "ea4aea8ed0814bba97f128097ec5ccf7",
            "b24ac43b5c434e6784edf164830b01bd",
            "eb439848569e46769bb53fa55daa7eb7",
            "71f39f9e61254218b5d47035c7b5cee4",
            "84186bddfc5246d5a85cfaab1bfd7e38",
            "c2488d88721446a7b41d87d76606560a",
            "68508f3c7f784b1f9489bea9ddfdef74",
            "14786981eafa42c48b71fefb288da142",
            "3bc8cd564dbe441db44647f1b0dfc72a",
            "f184c14577cb40ddb911483c4aaa3ee7",
            "228fd49e77f345d7a143e38cad3e3da2"
          ]
        },
        "id": "m4YwOK83_NlT",
        "outputId": "0a02ba43-f683-48b2-e131-eb49108d692e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/69.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d7cf6288f514123978acaa25e37db6f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea4aea8ed0814bba97f128097ec5ccf7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4)\n"
      ],
      "metadata": {
        "id": "MEG1h4L5_XuO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimized Data Transform Pipeline\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224), interpolation=InterpolationMode.BICUBIC),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "])\n"
      ],
      "metadata": {
        "id": "YHWd2SJN_Qiu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Food101 Dataset\n",
        "train_dataset = datasets.Food101(root='./data', split='train', transform=transform, download=True)\n",
        "val_dataset = datasets.Food101(root='./data', split='test', transform=transform, download=True)\n",
        "test_dataset = datasets.Food101(root='./data', split='test', transform=transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=torch.multiprocessing.cpu_count(),\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=torch.multiprocessing.cpu_count(),\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    num_workers=torch.multiprocessing.cpu_count(),\n",
        "    pin_memory=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBbkdwCy_TIH",
        "outputId": "113facf0-fd10-4610-fc07-ccd59ef5c4c3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://data.vision.ee.ethz.ch/cvl/food-101.tar.gz to ./data/food-101.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.00G/5.00G [02:34<00:00, 32.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/food-101.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()  # ENsuring Model is in training mode\n",
        "model = prepare_qat(model, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lve8wMgFB-3T",
        "outputId": "3d6e4f0d-347b-42bf-ae3c-9ace889bb2d0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/ao/quantization/quantize.py:392: UserWarning: None of the submodule got qconfig applied. Make sure you passed correct configuration through `qconfig_dict` or by assigning the `.qconfig` attribute directly on submodules\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "\n",
        "qconfig = get_default_qat_qconfig(\"fbgemm\")\n",
        "model.qconfig = qconfig\n",
        "model = prepare_qat(model, inplace=True)\n"
      ],
      "metadata": {
        "id": "fR2A2SPj_c9P"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_qat_model(model, dataloader, optimizer, criterion, device, epochs=1, save_dir=\"qat_checkpoints\"):\n",
        "    model.train()\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss, correct, total = 0.0, 0, 0\n",
        "        with tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\") as tepoch:\n",
        "            for images, labels in tepoch:\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(images).logits\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "                correct += (preds == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "\n",
        "                running_loss = total_loss / total\n",
        "                running_accuracy = 100.0 * correct / total\n",
        "\n",
        "                tepoch.set_postfix(loss=running_loss, accuracy=running_accuracy)\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader.dataset)\n",
        "        accuracy = 100.0 * correct / total\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "        checkpoint_path = os.path.join(save_dir, f\"checkpoint_epoch_{epoch+1}.pth\")\n",
        "        torch.save(model.state_dict(), checkpoint_path)\n",
        "        print(f\"Checkpoint saved at {checkpoint_path}\")"
      ],
      "metadata": {
        "id": "7xSx3XR6_lLB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_qat_model(model, train_loader, optimizer, criterion, epochs=1, device=device)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "collapsed": true,
        "id": "3aJbzxaE_mq6",
        "outputId": "f9eac852-7403-448e-a099-95b4ca522b75"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/1:   0%|          | 9/2368 [00:11<51:18,  1.30s/it, accuracy=3.82, loss=0.148]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-3638162663b4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# training call (uncomment when you have train_loader):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_qat_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-366c331a8065>\u001b[0m in \u001b[0;36mtrain_qat_model\u001b[0;34m(model, dataloader, optimizer, criterion, device, epochs, save_dir)\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                 \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.ao.quantization import convert\n",
        "quantized_model = convert(model)"
      ],
      "metadata": {
        "id": "Kj4mqwRsaoGi"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate_model(model, dataloader, device):\n",
        "    correct, total = 0, 0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(images).logits\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    # Calculate Metrics\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "\n",
        "    # Print Results\n",
        "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall:    {recall:.4f}\")\n",
        "    print(f\"F1 Score:  {f1:.4f}\")\n",
        "\n",
        "    return accuracy, precision, recall, f1\n"
      ],
      "metadata": {
        "id": "KhMOfIkXfUxT"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all layers and check their data type\n",
        "for name, module in quantized_model.named_modules():\n",
        "    # For layers with parameters\n",
        "    if hasattr(module, 'weight'):\n",
        "        print(f\"Layer: {name}\")\n",
        "        print(f\"  Type: {type(module)}\")\n",
        "        print(f\"  Weight dtype: {module.weight.dtype}\")\n",
        "        print(f\"  Device: {module.weight.device}\")\n",
        "        print(\"-\" * 40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "axJvi5drar3m",
        "outputId": "15dd5caa-0e76-4bbf-fd2b-aa3024fd3306"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: vit.embeddings.patch_embeddings.projection\n",
            "  Type: <class 'torch.nn.modules.conv.Conv2d'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.0.attention.attention.query\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.0.attention.attention.key\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.0.attention.attention.value\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.0.attention.output.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.0.intermediate.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.0.output.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.0.layernorm_before\n",
            "  Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.0.layernorm_after\n",
            "  Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.1.attention.attention.query\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.1.attention.attention.key\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.1.attention.attention.value\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.1.attention.output.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.1.intermediate.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.1.output.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.1.layernorm_before\n",
            "  Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.1.layernorm_after\n",
            "  Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.2.attention.attention.query\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.2.attention.attention.key\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.2.attention.attention.value\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.2.attention.output.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.2.intermediate.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.2.output.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.2.layernorm_before\n",
            "  Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.2.layernorm_after\n",
            "  Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.3.attention.attention.query\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.3.attention.attention.key\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.3.attention.attention.value\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.3.attention.output.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.3.intermediate.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.3.output.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.3.layernorm_before\n",
            "  Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.3.layernorm_after\n",
            "  Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.4.attention.attention.query\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.4.attention.attention.key\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.4.attention.attention.value\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.4.attention.output.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.4.intermediate.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.4.output.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.4.layernorm_before\n",
            "  Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.4.layernorm_after\n",
            "  Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.5.attention.attention.query\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.5.attention.attention.key\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.5.attention.attention.value\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.5.attention.output.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.5.intermediate.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.5.output.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.5.layernorm_before\n",
            "  Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.5.layernorm_after\n",
            "  Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.6.attention.attention.query\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.6.attention.attention.key\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.6.attention.attention.value\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.6.attention.output.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.6.intermediate.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.6.output.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.6.layernorm_before\n",
            "  Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.6.layernorm_after\n",
            "  Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.7.attention.attention.query\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.7.attention.attention.key\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.7.attention.attention.value\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.7.attention.output.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.7.intermediate.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.7.output.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.7.layernorm_before\n",
            "  Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.7.layernorm_after\n",
            "  Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.8.attention.attention.query\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.8.attention.attention.key\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.8.attention.attention.value\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.8.attention.output.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.8.intermediate.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.8.output.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.8.layernorm_before\n",
            "  Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.8.layernorm_after\n",
            "  Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.9.attention.attention.query\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.9.attention.attention.key\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.9.attention.attention.value\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.9.attention.output.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.9.intermediate.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.9.output.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.9.layernorm_before\n",
            "  Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.9.layernorm_after\n",
            "  Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.10.attention.attention.query\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.10.attention.attention.key\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.10.attention.attention.value\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.10.attention.output.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.10.intermediate.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.10.output.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.10.layernorm_before\n",
            "  Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.10.layernorm_after\n",
            "  Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.11.attention.attention.query\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.11.attention.attention.key\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.11.attention.attention.value\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.11.attention.output.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.11.intermediate.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.11.output.dense\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.11.layernorm_before\n",
            "  Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.encoder.layer.11.layernorm_after\n",
            "  Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: vit.layernorm\n",
            "  Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n",
            "Layer: classifier\n",
            "  Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "  Weight dtype: torch.float32\n",
            "  Device: cuda:0\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "neBUzUWbWXIN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}